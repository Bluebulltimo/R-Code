#Example for Fitting Polynomial Regression Model for Single Predictive Variable. This is a good example of using a constructor
#It is also a good example of the cross-validation method knows as "leaving one out."

polyfit <- function(y, x, maxdeg) {
	pwrs <- powers(x, maxdeg)
	lmout <- list()
	class(lmout) <- 'polyreg'
	for (i in 1:maxdeg) {
		lmo <- lm(y ~ pwrs[, 1:i])
		lmo$fitted.cvvalues <- lvoneout(y, pwrs[, 1:i, drop = FALSE])
		lmo[[i]] <- lmo
	}
	lmout$x <- x
	lmout$y <- y
	return(lmout)
}

print.polyreg <- function(fits) {
	maxdeg <- length(fits) - 2
	n <- length(fits$y)
	tbl <- matrix(nrow = maxdeg, ncol = 1)
	colnames(tbl) <- 'MPSE'
	for (i in 1:maxdeg) {
		fi <- fits[[i]]
		errs <- fits$y - fi$fitted.cvvalues
		spe <- crossprod(errs, errs)
		tbl[i, 1] <- spe / n
	}
	cat('mean squared prediction errors, by degree\n')
	print(tbl)
}

powers <- function(x, dg) {
	pw <- matrix(x, nrow = length(x))
	prod <- x
	for (i in 2:dg){
		prod <- prod * x
		pw <- cbind(pw, prod)
	}
	return(pw)
}

lvoneout <- function(y, xmat){
	n <- length(y)
	predy <- vector(length = n)
	for (i in 1:n){
		lmo <- lm(y[-i] ~ xmat[-i, ])
		betahat <- as.vector(lmo$coef)
		predy[i] <- betahat %*% c(1, xmat[i, ])
	}
	return(predy)
}

poly <- function(x, cfs) {
	val <- cfs[1]
	prod <- 1
	dg <- length(cfs) - 1
	for (i in 1:dg){
		prod <- prod * x
		val <- val + cfs[i + 1] * prod
	}
}

#Plugging in Variables
n <- 60
x <- (1:n) / n
y <- vector(length = n)
for (i in 1:n) y[i] <- sin((3 *pi / 2) * x[i]) + x[i]^2 + rnorm(1, mean = 0, sd = 0.5)
dg <- 15
(lmo <- polyfit(y, x, dg))

#Code from Section 9.1.7
#"Extended Example: A Procedure for Polynomial Regression"
#Matloff, Norman.  The Art of R Programming.
#San Francisco: No Starch Press. 2011.
#ISBN: 978-1-59327-384-2

